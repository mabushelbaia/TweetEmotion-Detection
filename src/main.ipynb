{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 22761 positive tweets in our dataset.\n",
      "We have 22514 negative tweets in our dataset.\n",
      "We have 45275 tweets in our dataset.\n",
      "A sample of the data\n",
      "       Label                                              Tweet\n",
      "3645    neg  Ø§Ù„Ù„Ù‡ ÙŠØ¹ÙŠÙ†Ù†Ø§ Ø§Ù„Ø­ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù†Ø§ Ø§Ù„ÙŠ Ø¨Ø§Ø± Ø¨Ø£Ù…ÙŠ...\n",
      "10209   pos  ÙƒÙ† Ùƒ Ù†Ø¨ØªØ© Ø£Ø²Ù‡Ø±Øª Ø±ØºÙ… Ø§Ù„Ø­Ø·Ø§Ù… ! ðŸŒ¸ðŸƒ ÙƒÙ† Ùƒ Ø¶ÙˆØ¡ ÙŠØ®ØªØ±Ù‚...\n",
      "4903    pos  #Ø­ÙÙŠØ¯Ø§Øª_Ø§Ù„ÙØ§Ø±ÙˆÙ‚ ( Ù‚Ø§Ù„ Ø£Ø®Ø±Ù‚ØªÙ‡Ø§ Ù„ØªØºØ±Ù‚ Ø£Ù‡Ù„Ù‡Ø§ ) ÙƒÙ…...\n",
      "19853   neg          ÙˆÙ…ÙÙŠØ´ ØµØ­ÙŠØ§Ù† Ø¨Ø¯Ø±ÙŠ Ø¹Ù„Ø´Ø§Ù† ÙˆØ±Ø§Ùƒ Ù…Ø®Ø±ÙˆØ¨Ø© ÙƒÙ„ÙŠØ© ðŸ˜¢\n",
      "20955   pos  #Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„ Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ Ø®Ø¨ÙŠØ± Ø§Ù„Ø­ÙƒÙŠÙ… Ù„Ù‚Ù†Ø§Ø© K ...\n"
     ]
    }
   ],
   "source": [
    "positive_tweets = pd.read_csv('../data/Positive_Tweets.tsv', sep='\\t', header=None)\n",
    "print(\"We have {} positive tweets in our dataset.\".format(len(positive_tweets)))\n",
    "negative_tweets = pd.read_csv('../data/Negative_Tweets.tsv', sep='\\t', header=None)\n",
    "print(\"We have {} negative tweets in our dataset.\".format(len(negative_tweets)))\n",
    "all_tweets = pd.concat([positive_tweets, negative_tweets])\n",
    "all_tweets.columns = ['Label', 'Tweet']\n",
    "print(\"We have {} tweets in our dataset.\".format(len(all_tweets)))\n",
    "#A random sample of 5 tweets\n",
    "print(\"A sample of the data\\n\", all_tweets.sample(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing Data\n",
    "\n",
    "in this part we will preprocces the data and make it ready for the model\n",
    "- remove mentions, hashtags, and links\n",
    "- remove stop words, that are words that are not important in the context of the sentence\n",
    "- remove punctuations\n",
    "- replace emojis with their meaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procces_tweet(tweet: str) -> str:\n",
    "    \n",
    "    # Remove all mentions, hashtags, links, and special characters\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+|@\\S+|#\\S+', '', tweet, flags=re.MULTILINE)\n",
    "    tweet = tweet.replace('Ø£', 'Ø§').replace('Ø¥', 'Ø§').replace('Ø¢', 'Ø§')\n",
    "    tweet = tweet.replace('Ø©', 'Ù‡').replace('Ù‰', 'ÙŠ').replace('Ø¤', 'Ùˆ')\n",
    "\n",
    "    # Remove all emojis and emoticons and replace them with unicode\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    \n",
    "    # Tokinize the tweet\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Remove all stop words, stop words are words that do not add any meaning to the sentence\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    # Stemming, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form\n",
    "    stemmer = SnowballStemmer('arabic')\n",
    "    stemmed_tokens = [stemmer.stem(w) for w in filtered_tokens]\n",
    "    \n",
    "    return \" \".join(stemmed_tokens)\n",
    "\n",
    "all_tweets['Filtered_Tweet'] = all_tweets['Tweet'].apply(procces_tweet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "In this part we will extract the features from the data, we will use the TF-IDF to extract the features, and what TF-IDF does is that it gives a score to each word in the sentence, and the score is based on how many times the word appears in the sentence, and how many times the word appears in the whole dataset, and the score is calculated by this formula:\n",
    "\n",
    "$$score = \\frac{\\text{number of times the word appears in the sentence}}{\\text{number of words in the sentence}} \\cdot \\log{\\frac{\\text{number of sentences}}{\\text{number of sentences that contain the word}}}$$\n",
    "\n",
    "Additonally we are going to use 75% of the data for training, and 25% for testing, and we are going to use 5-fold cross validation to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/features.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_tweets['Filtered_Tweet'].values, all_tweets['Label'].values, test_size=0.25)\n",
    "\n",
    "# Train on the training data and transform the training and testing data\n",
    "feature_extraction = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "joblib.dump(feature_extraction, '../models/features.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "We will use three models to train the data, a Naive Bayes model, a Search Tree model, and a not-assigned model, we will train the data in 5-fold cross validation, on a 75% training set and a 25% test set.\n",
    "\n",
    "## Naive Bayes Classifier\n",
    "Naive Bayes is a probabilistic model that uses Bayes' theorem to predict the class of a given data point. It is a simple model that is easy to implement and is very fast. It is also very effective in text classification problems. The model is based on the assumption that the features are independent of each other, which is not true in most cases, but it still works well in practice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 - 25 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.90      0.87      5649\n",
      "         pos       0.90      0.82      0.86      5670\n",
      "\n",
      "    accuracy                           0.86     11319\n",
      "   macro avg       0.87      0.86      0.86     11319\n",
      "weighted avg       0.87      0.86      0.86     11319\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5102  547]\n",
      " [ 995 4675]]\n",
      "True Positives (TP) =  5102\n",
      "False Positives (FP) =  547\n",
      "False Negatives (FN) =  995\n",
      "True Negatives (TN) =  4675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/NaiveBayes.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train a Naive Bayes classifier using 5-fold cross-validation\n",
    "NaiveBayes_Classifer = MultinomialNB()\n",
    "NaiveBayes_Classifer.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate the classifier using 5-fold cross-validation\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = NaiveBayes_Classifer.score(X_test_features, y_test)\n",
    "y_pred = NaiveBayes_Classifer.predict(X_test_features)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"True Positives (TP) = \", cm[0][0])\n",
    "print(\"False Positives (FP) = \", cm[0][1])\n",
    "print(\"False Negatives (FN) = \", cm[1][0])\n",
    "print(\"True Negatives (TN) = \", cm[1][1])\n",
    "joblib.dump(NaiveBayes_Classifer, '../models/NaiveBayes.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.90      0.87     22514\n",
      "         pos       0.90      0.83      0.86     22761\n",
      "\n",
      "    accuracy                           0.87     45275\n",
      "   macro avg       0.87      0.87      0.87     45275\n",
      "weighted avg       0.87      0.87      0.87     45275\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20308  2206]\n",
      " [ 3835 18926]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/naive_bayes_5f.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "naive_bayes_5f = MultinomialNB()\n",
    "\n",
    "# Define the cross-validation splitter\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Define the evaluation metrics\n",
    "metrics = {'accuracy': make_scorer(accuracy_score), \n",
    "           'precision': make_scorer(precision_score, pos_label='pos'), \n",
    "           'recall': make_scorer(recall_score, pos_label='pos'), \n",
    "           'f1': make_scorer(f1_score, pos_label='pos')}\n",
    "\n",
    "# Fit and evaluate the model with 5-fold cross-validation\n",
    "X = all_tweets['Filtered_Tweet'].values\n",
    "y = all_tweets['Label'].values\n",
    "y_preds = cross_val_predict(naive_bayes_5f, feature_extraction.fit_transform(X), y, cv=kf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y, y_preds))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y, y_preds))\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "naive_bayes_5f.fit(feature_extraction.fit_transform(X), y)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(naive_bayes_5f, '../models/naive_bayes_5f.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "We use Random Forest Classifier to train the data, Random Forest is an ensemble learning method for classification, regression, and other tasks, that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "### 75 - 25 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.93      0.93      0.93      5649\n",
      "         pos       0.93      0.93      0.93      5670\n",
      "\n",
      "    accuracy                           0.93     11319\n",
      "   macro avg       0.93      0.93      0.93     11319\n",
      "weighted avg       0.93      0.93      0.93     11319\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5261  388]\n",
      " [ 378 5292]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/RandomFortress.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train a decision tree classifier on the features\n",
    "RandomForest_Classifier = RandomForestClassifier(n_estimators=100)\n",
    "RandomForest_Classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = RandomForest_Classifier.score(X_test_features, y_test)\n",
    "y_pred = RandomForest_Classifier.predict(X_test_features)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "joblib.dump(RandomForest_Classifier, '../models/RandomFortress.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.92      0.93     22514\n",
      "         pos       0.93      0.94      0.93     22761\n",
      "\n",
      "    accuracy                           0.93     45275\n",
      "   macro avg       0.93      0.93      0.93     45275\n",
      "weighted avg       0.93      0.93      0.93     45275\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20800  1714]\n",
      " [ 1346 21415]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the cross-validation splitter\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Define the evaluation metrics\n",
    "metrics = {'accuracy': make_scorer(accuracy_score), \n",
    "           'precision': make_scorer(precision_score, pos_label='pos'), \n",
    "           'recall': make_scorer(recall_score, pos_label='pos'), \n",
    "           'f1': make_scorer(f1_score, pos_label='pos')}\n",
    "\n",
    "# Fit and evaluate the model with 5-fold cross-validation\n",
    "X = all_tweets['Filtered_Tweet'].values\n",
    "y = all_tweets['Label'].values\n",
    "y_preds = cross_val_predict(rf_model, feature_extraction.fit_transform(X), y, cv=kf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y, y_preds))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y, y_preds))\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "rf_model.fit(feature_extraction.fit_transform(X), y)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(rf_model, '../models/RandomFortress_5f.joblib')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs (Support Vector Machines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = svm_classifier.score(X_test_features, y_test)\n",
    "y_pred = svm_classifier.predict(X_test_features)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "joblib.dump(svm_classifier, '../models/SVM.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model\n",
    "svc_model_5f = SVC(kernel='linear')\n",
    "\n",
    "# Define the cross-validation splitter\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Define the evaluation metrics\n",
    "metrics = {'accuracy': make_scorer(accuracy_score), \n",
    "           'precision': make_scorer(precision_score, pos_label='pos'), \n",
    "           'recall': make_scorer(recall_score, pos_label='pos'), \n",
    "           'f1': make_scorer(f1_score, pos_label='pos')}\n",
    "\n",
    "# Fit and evaluate the model with 5-fold cross-validation\n",
    "X = all_tweets['Filtered_Tweet'].values\n",
    "y = all_tweets['Label'].values\n",
    "y_preds = cross_val_predict(svc_model_5f, feature_extraction.fit_transform(X), y, cv=kf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y, y_preds))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y, y_preds))\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "svc_model_5f.fit(feature_extraction.fit_transform(X), y)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(svc_model_5f, '../models/svc_model_5f.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "454fc107102943f3aab8ff5713912a5cbd72710550c047b68ef32412481257e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
